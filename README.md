# Summary of scraping scripts


# Wikipedia
This was an early attempt to get data from a web page. It takes some elements from a table and converts them into a list.
Modules:

# review_scores
Created to learn how to scrape from multiple pages and put into a single dataframe. 
Modules: beautifulsoup, requests, pandas, ...

# running_data_multiple_page_scrape
To extract my data from a well known Saturday morning running event. Creates a dataframe following scraping from multiple pages and pulling in various other elements to label graphs of data and calculate summary statistics. 
Modules: beautifulsoup, soupstrainer, requests, pandas, re (?), itertools, matplotlib, numpy, datetime, time
Check all above currently being used (and clear)
This was written in Jupyter notebooks (as the others were) and the next step is to split the cells into different modules (?)
Also in progress of extracting all data into a summary dataframe (a bit like the one of the athlete summmary page)





